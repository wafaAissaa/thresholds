{
 "cells": [
  {
   "cell_type": "code",
   "id": "6ab72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:20:01.674663Z",
     "start_time": "2025-05-07T13:20:01.523838Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T14:38:54.079955Z",
     "start_time": "2025-03-28T14:38:54.075587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./outputs/422.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data['features'].keys())"
   ],
   "id": "23e5b166",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['word_count', 'sentence_count', 'document_length', 'sophisticated_ratio', 'concrete_ratio', 'lexical_diversity', 'hapax_legomena_ratio_lemma', 'ratio_passive_per_token', 'ratio_passive_per_verb', 'total_token_ratio_passive', 'max_size_passive', 'ratio_coordination_per_token', 'total_token_ratio_coordination', 'max_size_coordination', 'ratio_clitic_per_token', 'ratio_pre_clitic_pronouns_per_token', 'ratio_post_clitic_pronouns_per_token', 'ratio_aux_verbs_per_token', 'ratio_aux_verbs_per_verb', 'total_token_ratio_aux_verbs', 'max_size_aux_verbs', 'ratio_named_entities_per_token', 'ratio_named_entities_per_verb', 'total_token_ratio_named_entities', 'max_size_named_entities', 'ratio_subordination_per_token', 'ratio_subordination_per_verb', 'total_token_ratio_subordination', 'max_size_subordination', 'max_size_np_pp_modifiers'])\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:57:50.453763Z",
     "start_time": "2025-03-28T16:57:50.029905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to the folder containing JSON files\n",
    "folder_path = \"./outputs\"\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):  # Check if the file has a .json extension\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Open and load the JSON file\n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "                #print(data['features'].keys())\n",
    "                # Check if \"error\" key exists in the JSON data\n",
    "                if \"error\" in data:\n",
    "                    print(f\"'error' key found in: {filename}\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Could not decode JSON in file: {filename}\")"
   ],
   "id": "237204a3797c037d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:11:26.524597Z",
     "start_time": "2025-03-28T17:11:24.017254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to the folder containing JSON files\n",
    "folder_path = \"./outputs\"\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):  # Check if the file has a .json extension\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Open and load the JSON file\n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "                #print(data['features'].keys())\n",
    "                # Check if \"error\" key exists in the JSON data\n",
    "                for k, v in data['sentences'].items():\n",
    "                    for k1, v1 in v['words'].items():\n",
    "                        v1[\"lexical_frequency\"] = v1.pop(\"lexical frequency\")\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(data, f)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Could not decode JSON in file: {filename}\")"
   ],
   "id": "b374feba395ccb41",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T15:56:50.130430Z",
     "start_time": "2025-03-26T15:56:50.122070Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'sentences'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3,
   "source": "data.keys()",
   "id": "2220f862"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fdaf55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T15:58:40.517322Z",
     "start_time": "2025-03-26T15:58:40.512260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parse_depth': 3,\n",
       " 'sentence_length': 3,\n",
       " 'max_size_aux_verbs': 0,\n",
       " 'max_size_named_entities': 1,\n",
       " 'max_size_subordination': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentences']['0']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcbfba9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T16:03:44.597331Z",
     "start_time": "2025-03-26T16:03:44.593440Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_N1 = {\"sentence-token-level\": {}, \"document-token-level\": {}, \n",
    "                \"document-sentence-level\": {}, \"document-document-level\": {},\n",
    "               \"sentence-level\": {}, \"token-level-high\": {},\n",
    "               \"token-level-low\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "id": "9efe7c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:57:57.140454Z",
     "start_time": "2025-03-28T16:57:57.126327Z"
    }
   },
   "source": "df = pd.read_csv('./Qualtrics_Annotations_B.csv', delimiter=\"\\t\", index_col=\"text_indice\")",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6986ee1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:57:58.127643Z",
     "start_time": "2025-03-28T16:57:58.122890Z"
    }
   },
   "source": [
    "classes = {'Très Facile':'N1', 'Facile': 'N2', 'Accessible':'N3','+Complexe':'N4'}\n",
    "thresholds = {'N1':{}, 'N2':{}, 'N3': {}, 'N4':{}}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "aea177d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:57:59.627931Z",
     "start_time": "2025-03-28T16:57:59.624996Z"
    }
   },
   "source": [
    "def get_bounds(values): \n",
    "    Q1 = np.percentile(values, 25)  # First quartile (25th percentile)\n",
    "    Q3 = np.percentile(values, 75)  # Third quartile (75th percentile)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "set(errors) #in output v0 [495, 656, 1041, 1552]",
   "id": "4c6a86d36de70d86"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4d7364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:23:04.646308Z",
     "start_time": "2025-03-26T22:23:04.641734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(errors)) #in output"
   ]
  },
  {
   "cell_type": "code",
   "id": "24c0e12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:58:01.287866Z",
     "start_time": "2025-03-28T16:58:01.285648Z"
    }
   },
   "source": "outputs_path = \"./outputs\"",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T15:57:21.241820Z",
     "start_time": "2025-03-28T15:57:21.174570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_token_level = {\n",
    "    \"max_size_aux_verbs\": None,\n",
    "    \"max_size_passive\": None,\n",
    "    \"max_size_named_entities\": None,\n",
    "    \"max_size_np_pp_modifiers\": None,\n",
    "    \"max_size_subordination\": None,\n",
    "    \"max_size_coordination\": None,\n",
    "    }\n",
    "document_token_level = {\n",
    "    \"total_token_ratio_aux_verbs\": None,\n",
    "    \"total_token_ratio_passive\": None,\n",
    "    \"total_token_ratio_named_entities\": None,\n",
    "    \"total_token_ratio_subordination\": None,\n",
    "    \"ratio_clitic_per_token\": None,\n",
    "    \"ratio_post_clitic_pronouns_per_token\": None,\n",
    "    \"ratio_pre_clitic_pronouns_per_token\": None,\n",
    "    \"ratio_named_entities_per_token\": None,\n",
    "    \"ratio_aux_verbs_per_token\": None,\n",
    "    \"ratio_subordination_per_token\": None,\n",
    "    \"ratio_passive_per_token\": None,\n",
    "    \"sophisticated_ratio\": None,\n",
    "    \"concrete_ratio\": None,\n",
    "    \"hapax_legomena_ratio_lemma\": None,\n",
    "    # \"p0-p75_freq_ratio\": None, missing from output\n",
    "    # \"p0-p75_freq_lemma_ratio\": None, missing from output\n",
    "    \"ratio_aux_verbs_per_verb\": None,\n",
    "    \"ratio_subordination_per_verb\": None,\n",
    "    \"ratio_passive_per_verb\": None,\n",
    "    \"ratio_coordination_per_token\": None,\n",
    "    \"total_token_ratio_coordination\": None,\n",
    "    \"ratio_coordination_per_token\": None,\n",
    "}\n",
    "\n",
    "sentence_level= {\n",
    "      \"parse_depth\": None,\n",
    "      \"words_after_verb\": None,\n",
    "      \"words_before_verb\": None,\n",
    "      \"sentence_length\": None\n",
    "    }\n",
    "\n",
    "document_document_level = {\n",
    "    \"lexical_diversity\": None}\n",
    "\n",
    "token_level_high = {\n",
    "      \"word_length\": None,\n",
    "      \"word_syllables\": None,\n",
    "      \"ortho_neighbors\": None,\n",
    "      \"ortho_neighbors_+freq_cum\": None,\n",
    "      \"age_of_acquisition\": None,\n",
    "      \"complexity\": None,\n",
    "    }\n",
    "\n",
    "token_level_low = {\n",
    "      \"familiarity\": None,\n",
    "      \"lexical frequency\": None\n",
    "    }\n",
    "\n",
    "thresholds_init = {\"sentence-token-level\": sentence_token_level, \"document-token-level\": document_token_level, \"sentence_level\": sentence_level, \"document-document-level\":document_document_level, \"token-level-high\": token_level_high, \"token-level-low\": token_level_low}"
   ],
   "id": "deb558333f814fb0",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T15:58:59.071423Z",
     "start_time": "2025-03-28T15:58:59.066024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = {'Très Facile':'N1', 'Facile': 'N2', 'Accessible':'N3','+Complexe':'N4'}\n",
    "\n",
    "thresholds = {'N1':thresholds_init, 'N2':thresholds_init, 'N3': thresholds_init, 'N4':thresholds_init}\n",
    "\n",
    "distrib_levels = {\"sentence-token-level\": \"document\", \"document-token-level\": \"document\", \"sentence_level\": \"sentence\", \"document-document-level\": \"document\", \"token-level-high\": \"token\", \"token-level-low\": \"token\"}\n",
    "\n",
    "def compute_thresholds(thresholds, df):\n",
    "\n",
    "    for classe, niveau in classes.items():\n",
    "        indexes = df[df[\"gold_score_20_label\"] == classe].index\n",
    "\n",
    "        dictionnary = thresholds[niveau]\n",
    "        for key, dictionnary2 in dictionnary.items():\n",
    "            for phenomenon in dictionnary2.keys():\n",
    "                values = []\n",
    "                for i in indexes:\n",
    "                    with open('%s/%s.json' %(outputs_path,i), 'r') as file:\n",
    "                        data = json.load(file)\n",
    "                    if 'error' in data.keys():\n",
    "                        errors.append(i)\n",
    "                        print('error in index %s' %i)\n",
    "                        continue\n",
    "                    if distrib_levels[key] == 'document':\n",
    "                        values.append(data['features'][phenomenon])\n",
    "                    elif distrib_levels[key] == 'sentence':\n",
    "                        for k, v in data['sentences'].items():\n",
    "                            values.append(v['features'][phenomenon])\n",
    "                    elif distrib_levels[key] == 'token':\n",
    "                        for k, v in data['sentences'].items():\n",
    "                            for k1, v1 in v['words'].items():\n",
    "                                if v1[phenomenon] != 'na': values.append(v1[phenomenon])\n",
    "\n",
    "                lower_bound, upper_bound = get_bounds(values)\n",
    "                print(phenomenon, lower_bound, upper_bound)\n",
    "                if key == 'token-level-low':\n",
    "                    dictionnary2[phenomenon] = round(lower_bound,4)\n",
    "                else:\n",
    "                    dictionnary2[phenomenon] = round(upper_bound,4)\n",
    "        return thresholds\n"
   ],
   "id": "345a5fd9914e33e7",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:29:51.027225Z",
     "start_time": "2025-03-28T16:29:50.697316Z"
    }
   },
   "cell_type": "code",
   "source": "compute_thresholds(thresholds, df)",
   "id": "705bd196e8df105a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size_aux_verbs -3.0 5.0\n",
      "max_size_passive 0.0 0.0\n",
      "max_size_named_entities -1.75 8.25\n",
      "max_size_np_pp_modifiers -19.0 37.0\n",
      "max_size_subordination -11.0 21.0\n",
      "max_size_coordination -0.5 3.5\n",
      "total_token_ratio_aux_verbs -0.05012531328320802 0.0835421888053467\n",
      "total_token_ratio_passive 0.0 0.0\n",
      "total_token_ratio_named_entities -0.10190537380000547 0.30000101982540595\n",
      "total_token_ratio_subordination -0.2264279019941056 0.4338324496984876\n",
      "ratio_clitic_per_token -0.14055299539170507 0.23425499231950844\n",
      "ratio_post_clitic_pronouns_per_token -0.11805555555555554 0.19675925925925924\n",
      "ratio_pre_clitic_pronouns_per_token -0.002747252747252747 0.004578754578754578\n",
      "ratio_named_entities_per_token -0.039792023741509544 0.12225224295901309\n",
      "ratio_aux_verbs_per_token -0.04222932954276238 0.07038221590460397\n",
      "ratio_subordination_per_token -0.01560482596994926 0.06056617259169818\n",
      "ratio_passive_per_token 0.0 0.0\n",
      "sophisticated_ratio 0.009183239740076565 0.8571819803832723\n",
      "concrete_ratio -0.1794021371424332 1.02221105385606\n",
      "hapax_legomena_ratio_lemma -0.0729197767597421 0.980227612835785\n",
      "ratio_aux_verbs_per_verb -0.30000000000000004 0.5\n",
      "ratio_subordination_per_verb -0.641304347826087 1.1847826086956523\n",
      "ratio_passive_per_verb 0.0 0.0\n",
      "ratio_coordination_per_token -0.0024583015287137373 0.04130969166102989\n",
      "total_token_ratio_coordination -0.012765635252462144 0.05995589898954608\n",
      "parse_depth 1.5 5.5\n",
      "words_after_verb -2.0 6.0\n",
      "words_before_verb -0.5 3.5\n",
      "sentence_length -2.125 18.875\n",
      "lexical_diversity 0.8096937361419068 1.114183758314856\n",
      "word_length -2.5 9.5\n",
      "word_syllables -1.5 2.5\n",
      "ortho_neighbors -19.0 37.0\n",
      "ortho_neighbors_+freq_cum -53199.770000000004 88770.55\n",
      "age_of_acquisition 1.61790878754171 8.16295884315907\n",
      "complexity -0.5 3.5\n",
      "familiarity 2.6964285714285654 9.410714285714285\n",
      "lexical frequency -9752.72999999975 16254.54999999985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'N1': {'sentence-token-level': {'max_size_aux_verbs': 5.0,\n",
       "   'max_size_passive': 0.0,\n",
       "   'max_size_named_entities': 8.25,\n",
       "   'max_size_np_pp_modifiers': 37.0,\n",
       "   'max_size_subordination': 21.0,\n",
       "   'max_size_coordination': 3.5},\n",
       "  'document-token-level': {'total_token_ratio_aux_verbs': 0.0835,\n",
       "   'total_token_ratio_passive': 0.0,\n",
       "   'total_token_ratio_named_entities': 0.3,\n",
       "   'total_token_ratio_subordination': 0.4338,\n",
       "   'ratio_clitic_per_token': 0.2343,\n",
       "   'ratio_post_clitic_pronouns_per_token': 0.1968,\n",
       "   'ratio_pre_clitic_pronouns_per_token': 0.0046,\n",
       "   'ratio_named_entities_per_token': 0.1223,\n",
       "   'ratio_aux_verbs_per_token': 0.0704,\n",
       "   'ratio_subordination_per_token': 0.0606,\n",
       "   'ratio_passive_per_token': 0.0,\n",
       "   'sophisticated_ratio': 0.8572,\n",
       "   'concrete_ratio': 1.0222,\n",
       "   'hapax_legomena_ratio_lemma': 0.9802,\n",
       "   'ratio_aux_verbs_per_verb': 0.5,\n",
       "   'ratio_subordination_per_verb': 1.1848,\n",
       "   'ratio_passive_per_verb': 0.0,\n",
       "   'ratio_coordination_per_token': 0.0413,\n",
       "   'total_token_ratio_coordination': 0.06},\n",
       "  'sentence_level': {'parse_depth': 5.5,\n",
       "   'words_after_verb': 6.0,\n",
       "   'words_before_verb': 3.5,\n",
       "   'sentence_length': 18.875},\n",
       "  'document-document-level': {'lexical_diversity': 1.1142},\n",
       "  'token-level-high': {'word_length': 9.5,\n",
       "   'word_syllables': 2.5,\n",
       "   'ortho_neighbors': 37.0,\n",
       "   'ortho_neighbors_+freq_cum': 88770.55,\n",
       "   'age_of_acquisition': 8.163,\n",
       "   'complexity': 3.5},\n",
       "  'token-level-low': {'familiarity': 2.6964, 'lexical frequency': -9752.73}},\n",
       " 'N2': {'sentence-token-level': {'max_size_aux_verbs': 5.0,\n",
       "   'max_size_passive': 0.0,\n",
       "   'max_size_named_entities': 8.25,\n",
       "   'max_size_np_pp_modifiers': 37.0,\n",
       "   'max_size_subordination': 21.0,\n",
       "   'max_size_coordination': 3.5},\n",
       "  'document-token-level': {'total_token_ratio_aux_verbs': 0.0835,\n",
       "   'total_token_ratio_passive': 0.0,\n",
       "   'total_token_ratio_named_entities': 0.3,\n",
       "   'total_token_ratio_subordination': 0.4338,\n",
       "   'ratio_clitic_per_token': 0.2343,\n",
       "   'ratio_post_clitic_pronouns_per_token': 0.1968,\n",
       "   'ratio_pre_clitic_pronouns_per_token': 0.0046,\n",
       "   'ratio_named_entities_per_token': 0.1223,\n",
       "   'ratio_aux_verbs_per_token': 0.0704,\n",
       "   'ratio_subordination_per_token': 0.0606,\n",
       "   'ratio_passive_per_token': 0.0,\n",
       "   'sophisticated_ratio': 0.8572,\n",
       "   'concrete_ratio': 1.0222,\n",
       "   'hapax_legomena_ratio_lemma': 0.9802,\n",
       "   'ratio_aux_verbs_per_verb': 0.5,\n",
       "   'ratio_subordination_per_verb': 1.1848,\n",
       "   'ratio_passive_per_verb': 0.0,\n",
       "   'ratio_coordination_per_token': 0.0413,\n",
       "   'total_token_ratio_coordination': 0.06},\n",
       "  'sentence_level': {'parse_depth': 5.5,\n",
       "   'words_after_verb': 6.0,\n",
       "   'words_before_verb': 3.5,\n",
       "   'sentence_length': 18.875},\n",
       "  'document-document-level': {'lexical_diversity': 1.1142},\n",
       "  'token-level-high': {'word_length': 9.5,\n",
       "   'word_syllables': 2.5,\n",
       "   'ortho_neighbors': 37.0,\n",
       "   'ortho_neighbors_+freq_cum': 88770.55,\n",
       "   'age_of_acquisition': 8.163,\n",
       "   'complexity': 3.5},\n",
       "  'token-level-low': {'familiarity': 2.6964, 'lexical frequency': -9752.73}},\n",
       " 'N3': {'sentence-token-level': {'max_size_aux_verbs': 5.0,\n",
       "   'max_size_passive': 0.0,\n",
       "   'max_size_named_entities': 8.25,\n",
       "   'max_size_np_pp_modifiers': 37.0,\n",
       "   'max_size_subordination': 21.0,\n",
       "   'max_size_coordination': 3.5},\n",
       "  'document-token-level': {'total_token_ratio_aux_verbs': 0.0835,\n",
       "   'total_token_ratio_passive': 0.0,\n",
       "   'total_token_ratio_named_entities': 0.3,\n",
       "   'total_token_ratio_subordination': 0.4338,\n",
       "   'ratio_clitic_per_token': 0.2343,\n",
       "   'ratio_post_clitic_pronouns_per_token': 0.1968,\n",
       "   'ratio_pre_clitic_pronouns_per_token': 0.0046,\n",
       "   'ratio_named_entities_per_token': 0.1223,\n",
       "   'ratio_aux_verbs_per_token': 0.0704,\n",
       "   'ratio_subordination_per_token': 0.0606,\n",
       "   'ratio_passive_per_token': 0.0,\n",
       "   'sophisticated_ratio': 0.8572,\n",
       "   'concrete_ratio': 1.0222,\n",
       "   'hapax_legomena_ratio_lemma': 0.9802,\n",
       "   'ratio_aux_verbs_per_verb': 0.5,\n",
       "   'ratio_subordination_per_verb': 1.1848,\n",
       "   'ratio_passive_per_verb': 0.0,\n",
       "   'ratio_coordination_per_token': 0.0413,\n",
       "   'total_token_ratio_coordination': 0.06},\n",
       "  'sentence_level': {'parse_depth': 5.5,\n",
       "   'words_after_verb': 6.0,\n",
       "   'words_before_verb': 3.5,\n",
       "   'sentence_length': 18.875},\n",
       "  'document-document-level': {'lexical_diversity': 1.1142},\n",
       "  'token-level-high': {'word_length': 9.5,\n",
       "   'word_syllables': 2.5,\n",
       "   'ortho_neighbors': 37.0,\n",
       "   'ortho_neighbors_+freq_cum': 88770.55,\n",
       "   'age_of_acquisition': 8.163,\n",
       "   'complexity': 3.5},\n",
       "  'token-level-low': {'familiarity': 2.6964, 'lexical frequency': -9752.73}},\n",
       " 'N4': {'sentence-token-level': {'max_size_aux_verbs': 5.0,\n",
       "   'max_size_passive': 0.0,\n",
       "   'max_size_named_entities': 8.25,\n",
       "   'max_size_np_pp_modifiers': 37.0,\n",
       "   'max_size_subordination': 21.0,\n",
       "   'max_size_coordination': 3.5},\n",
       "  'document-token-level': {'total_token_ratio_aux_verbs': 0.0835,\n",
       "   'total_token_ratio_passive': 0.0,\n",
       "   'total_token_ratio_named_entities': 0.3,\n",
       "   'total_token_ratio_subordination': 0.4338,\n",
       "   'ratio_clitic_per_token': 0.2343,\n",
       "   'ratio_post_clitic_pronouns_per_token': 0.1968,\n",
       "   'ratio_pre_clitic_pronouns_per_token': 0.0046,\n",
       "   'ratio_named_entities_per_token': 0.1223,\n",
       "   'ratio_aux_verbs_per_token': 0.0704,\n",
       "   'ratio_subordination_per_token': 0.0606,\n",
       "   'ratio_passive_per_token': 0.0,\n",
       "   'sophisticated_ratio': 0.8572,\n",
       "   'concrete_ratio': 1.0222,\n",
       "   'hapax_legomena_ratio_lemma': 0.9802,\n",
       "   'ratio_aux_verbs_per_verb': 0.5,\n",
       "   'ratio_subordination_per_verb': 1.1848,\n",
       "   'ratio_passive_per_verb': 0.0,\n",
       "   'ratio_coordination_per_token': 0.0413,\n",
       "   'total_token_ratio_coordination': 0.06},\n",
       "  'sentence_level': {'parse_depth': 5.5,\n",
       "   'words_after_verb': 6.0,\n",
       "   'words_before_verb': 3.5,\n",
       "   'sentence_length': 18.875},\n",
       "  'document-document-level': {'lexical_diversity': 1.1142},\n",
       "  'token-level-high': {'word_length': 9.5,\n",
       "   'word_syllables': 2.5,\n",
       "   'ortho_neighbors': 37.0,\n",
       "   'ortho_neighbors_+freq_cum': 88770.55,\n",
       "   'age_of_acquisition': 8.163,\n",
       "   'complexity': 3.5},\n",
       "  'token-level-low': {'familiarity': 2.6964, 'lexical frequency': -9752.73}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T15:33:02.560395Z",
     "start_time": "2025-03-28T15:33:02.351301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_token_level = {\n",
    "    \"max_size_aux_verbs\": None,\n",
    "    \"max_size_passive\": None,\n",
    "    \"max_size_named_entities\": None,\n",
    "    \"max_size_np_pp_modifiers\": None,\n",
    "    \"max_size_subordination\": None,\n",
    "    \"max_size_coordination\": None,\n",
    "    }\n",
    "compute_thresholds(sentence_token_level, \"document\", \"upper\")"
   ],
   "id": "fd791931fc10c843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size_aux_verbs -3.0 5.0\n",
      "max_size_passive 0.0 0.0\n",
      "max_size_named_entities -1.75 8.25\n",
      "max_size_np_pp_modifiers -19.0 37.0\n",
      "max_size_subordination -11.0 21.0\n",
      "max_size_coordination -0.5 3.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_size_aux_verbs': 5.0,\n",
       " 'max_size_passive': 0.0,\n",
       " 'max_size_named_entities': 8.25,\n",
       " 'max_size_np_pp_modifiers': 37.0,\n",
       " 'max_size_subordination': 21.0,\n",
       " 'max_size_coordination': 3.5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "e12920d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:59:28.425958Z",
     "start_time": "2025-03-28T16:59:25.806677Z"
    }
   },
   "source": [
    "errors = []\n",
    "\n",
    "sentence_token_level = {\n",
    "    \"max_size_aux_verbs\": None,\n",
    "    \"max_size_passive\": None, \n",
    "    \"max_size_named_entities\": None,\n",
    "    \"max_size_np_pp_modifiers\": None, \n",
    "    \"max_size_subordination\": None,\n",
    "    \"max_size_coordination\": None,\n",
    "    }\n",
    "\n",
    "for label, level in classes.items():\n",
    "    \n",
    "    indexes = df[df[\"gold_score_20_label\"] == label].index\n",
    "    \n",
    "    dictionnary = sentence_token_level.copy()\n",
    "\n",
    "    for phenomenon in dictionnary.keys():\n",
    "        values = []\n",
    "        for i in indexes:\n",
    "            with open('%s/%s.json' %(outputs_path,i), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            values.append(data['features'][phenomenon])\n",
    "        #values = [x for x in values if x != 0]\n",
    "        lower_bound, upper_bound = get_bounds(values)\n",
    "        print(phenomenon, level, upper_bound)\n",
    "        dictionnary[phenomenon] = round(upper_bound, 4)\n",
    "        \n",
    "    thresholds[level][\"sentence-token-level\"] = dictionnary"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size_aux_verbs N1 5.0\n",
      "max_size_passive N1 0.0\n",
      "max_size_named_entities N1 8.25\n",
      "max_size_np_pp_modifiers N1 37.0\n",
      "max_size_subordination N1 21.0\n",
      "max_size_coordination N1 3.5\n",
      "max_size_aux_verbs N2 5.0\n",
      "max_size_passive N2 5.0\n",
      "max_size_named_entities N2 7.0\n",
      "max_size_np_pp_modifiers N2 14.0\n",
      "max_size_subordination N2 30.5\n",
      "max_size_coordination N2 6.0\n",
      "max_size_aux_verbs N3 2.0\n",
      "max_size_passive N3 5.0\n",
      "max_size_named_entities N3 9.5\n",
      "max_size_np_pp_modifiers N3 17.5\n",
      "max_size_subordination N3 45.5\n",
      "max_size_coordination N3 6.0\n",
      "max_size_aux_verbs N4 2.0\n",
      "max_size_passive N4 5.0\n",
      "max_size_named_entities N4 7.625\n",
      "max_size_np_pp_modifiers N4 18.5\n",
      "max_size_subordination N4 51.125\n",
      "max_size_coordination N4 6.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:04:54.646284Z",
     "start_time": "2025-03-28T17:04:54.642988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./thresholds_v4.json' , 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for level in classes.values():\n",
    "    print(thresholds[level][\"sentence-token-level\"] == data[level][\"sentence-token-level\"])"
   ],
   "id": "b315754988df20a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:00:05.543898Z",
     "start_time": "2025-03-28T17:00:05.538421Z"
    }
   },
   "cell_type": "code",
   "source": "thresholds[\"N1\"][\"sentence-token-level\"]",
   "id": "cb68a05243e1360e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_size_aux_verbs': 5.0,\n",
       " 'max_size_passive': 0.0,\n",
       " 'max_size_named_entities': 8.25,\n",
       " 'max_size_np_pp_modifiers': 37.0,\n",
       " 'max_size_subordination': 21.0,\n",
       " 'max_size_coordination': 3.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:04:59.780286Z",
     "start_time": "2025-03-28T17:04:59.777114Z"
    }
   },
   "cell_type": "code",
   "source": "[data[level][\"sentence-token-level\"] for level in classes.values()]",
   "id": "26ad2d90153ffca5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_size_aux_verbs': 5.0,\n",
       "  'max_size_passive': 0.0,\n",
       "  'max_size_named_entities': 8.25,\n",
       "  'max_size_np_pp_modifiers': 37.0,\n",
       "  'max_size_subordination': 21.0,\n",
       "  'max_size_coordination': 3.5},\n",
       " {'max_size_aux_verbs': 5.0,\n",
       "  'max_size_passive': 5.0,\n",
       "  'max_size_named_entities': 7.0,\n",
       "  'max_size_np_pp_modifiers': 14.0,\n",
       "  'max_size_subordination': 30.5,\n",
       "  'max_size_coordination': 6.0},\n",
       " {'max_size_aux_verbs': 2.0,\n",
       "  'max_size_passive': 5.0,\n",
       "  'max_size_named_entities': 9.5,\n",
       "  'max_size_np_pp_modifiers': 17.5,\n",
       "  'max_size_subordination': 45.5,\n",
       "  'max_size_coordination': 6.0},\n",
       " {'max_size_aux_verbs': 2.0,\n",
       "  'max_size_passive': 5.0,\n",
       "  'max_size_named_entities': 7.625,\n",
       "  'max_size_np_pp_modifiers': 18.5,\n",
       "  'max_size_subordination': 51.125,\n",
       "  'max_size_coordination': 6.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "0542c1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:05:31.282600Z",
     "start_time": "2025-03-28T17:05:22.010476Z"
    }
   },
   "source": [
    "document_token_level = {\n",
    "    \"total_token_ratio_aux_verbs\": None,\n",
    "    \"total_token_ratio_passive\": None,\n",
    "    \"total_token_ratio_named_entities\": None,\n",
    "    \"total_token_ratio_subordination\": None,\n",
    "    \"ratio_clitic_per_token\": None,\n",
    "    \"ratio_post_clitic_pronouns_per_token\": None,\n",
    "    \"ratio_pre_clitic_pronouns_per_token\": None,\n",
    "    \"ratio_named_entities_per_token\": None,\n",
    "    \"ratio_aux_verbs_per_token\": None,\n",
    "    \"ratio_subordination_per_token\": None,\n",
    "    \"ratio_passive_per_token\": None,\n",
    "    \"sophisticated_ratio\": None,\n",
    "    \"concrete_ratio\": None,\n",
    "    \"hapax_legomena_ratio_lemma\": None,\n",
    "    # \"p0-p75_freq_ratio\": None, missing from output\n",
    "    # \"p0-p75_freq_lemma_ratio\": None, missing from output\n",
    "    \"ratio_aux_verbs_per_verb\": None,\n",
    "    \"ratio_subordination_per_verb\": None,\n",
    "    \"ratio_passive_per_verb\": None,\n",
    "    \"ratio_coordination_per_token\": None,\n",
    "    \"total_token_ratio_coordination\": None,\n",
    "    \"ratio_coordination_per_token\": None,\n",
    "}\n",
    "\n",
    "ignored, errors = [], []\n",
    "for label, level in classes.items():\n",
    "    \n",
    "    indexes = df[df[\"gold_score_20_label\"] == label].index\n",
    "    \n",
    "    dictionnary = document_token_level.copy()\n",
    "\n",
    "    for phenomenon in dictionnary.keys():\n",
    "        values = []\n",
    "        for i in indexes:\n",
    "            with open('%s/%s.json' %(outputs_path,i), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            if 'error' in data.keys() :\n",
    "                errors.append(i)\n",
    "                continue\n",
    "            values.append(data['features'][phenomenon])\n",
    "        #values = [x for x in values if x != 0]\n",
    "        if phenomenon in ignored: continue\n",
    "        lower_bound, upper_bound = get_bounds(values)\n",
    "        print(phenomenon, level, upper_bound)\n",
    "        dictionnary[phenomenon] = round(upper_bound, 4)\n",
    "        \n",
    "    thresholds[level][\"document-token-level\"] = dictionnary"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_token_ratio_aux_verbs N1 0.0835421888053467\n",
      "total_token_ratio_passive N1 0.0\n",
      "total_token_ratio_named_entities N1 0.30000101982540595\n",
      "total_token_ratio_subordination N1 0.4338324496984876\n",
      "ratio_clitic_per_token N1 0.23425499231950844\n",
      "ratio_post_clitic_pronouns_per_token N1 0.19675925925925924\n",
      "ratio_pre_clitic_pronouns_per_token N1 0.004578754578754578\n",
      "ratio_named_entities_per_token N1 0.12225224295901309\n",
      "ratio_aux_verbs_per_token N1 0.07038221590460397\n",
      "ratio_subordination_per_token N1 0.06056617259169818\n",
      "ratio_passive_per_token N1 0.0\n",
      "sophisticated_ratio N1 0.8571819803832723\n",
      "concrete_ratio N1 1.02221105385606\n",
      "hapax_legomena_ratio_lemma N1 0.980227612835785\n",
      "ratio_aux_verbs_per_verb N1 0.5\n",
      "ratio_subordination_per_verb N1 1.1847826086956523\n",
      "ratio_passive_per_verb N1 0.0\n",
      "ratio_coordination_per_token N1 0.04130969166102989\n",
      "total_token_ratio_coordination N1 0.05995589898954608\n",
      "total_token_ratio_aux_verbs N2 0.08571428571428572\n",
      "total_token_ratio_passive N2 0.017605633802816902\n",
      "total_token_ratio_named_entities N2 0.21332168942521434\n",
      "total_token_ratio_subordination N2 0.513648771610555\n",
      "ratio_clitic_per_token N2 0.12799552071668532\n",
      "ratio_post_clitic_pronouns_per_token N2 0.1324475736240442\n",
      "ratio_pre_clitic_pronouns_per_token N2 0.0\n",
      "ratio_named_entities_per_token N2 0.11076408254322365\n",
      "ratio_aux_verbs_per_token N2 0.05434782608695652\n",
      "ratio_subordination_per_token N2 0.06808858775811209\n",
      "ratio_passive_per_token N2 0.008223684210526315\n",
      "sophisticated_ratio N2 0.8407958395999058\n",
      "concrete_ratio N2 0.8100649350649352\n",
      "hapax_legomena_ratio_lemma N2 0.7031539888682745\n",
      "ratio_aux_verbs_per_verb N2 0.5\n",
      "ratio_subordination_per_verb N2 0.5800000000000001\n",
      "ratio_passive_per_verb N2 0.078125\n",
      "ratio_coordination_per_token N2 0.06869446343130553\n",
      "total_token_ratio_coordination N2 0.09106585591256713\n",
      "total_token_ratio_aux_verbs N3 0.09428862217574122\n",
      "total_token_ratio_passive N3 0.017316365979381444\n",
      "total_token_ratio_named_entities N3 0.19366561319807138\n",
      "total_token_ratio_subordination N3 0.6342653853858007\n",
      "ratio_clitic_per_token N3 0.106969121253118\n",
      "ratio_post_clitic_pronouns_per_token N3 0.1023482082591888\n",
      "ratio_pre_clitic_pronouns_per_token N3 0.006896590978082691\n",
      "ratio_named_entities_per_token N3 0.10347439533886243\n",
      "ratio_aux_verbs_per_token N3 0.054401648018140764\n",
      "ratio_subordination_per_token N3 0.06290695300045576\n",
      "ratio_passive_per_token N3 0.00832777692761734\n",
      "sophisticated_ratio N3 0.7498459034384206\n",
      "concrete_ratio N3 0.7628813512049921\n",
      "hapax_legomena_ratio_lemma N3 0.5995272547126391\n",
      "ratio_aux_verbs_per_verb N3 0.6251515151515151\n",
      "ratio_subordination_per_verb N3 0.5652295285359802\n",
      "ratio_passive_per_verb N3 0.08333333333333334\n",
      "ratio_coordination_per_token N3 0.06381157625194653\n",
      "total_token_ratio_coordination N3 0.09040055723737249\n",
      "total_token_ratio_aux_verbs N4 0.0720953303802141\n",
      "total_token_ratio_passive N4 0.014317134035443895\n",
      "total_token_ratio_named_entities N4 0.10480250442657502\n",
      "total_token_ratio_subordination N4 0.6283487442486431\n",
      "ratio_clitic_per_token N4 0.1186155216220586\n",
      "ratio_post_clitic_pronouns_per_token N4 0.12643283420262252\n",
      "ratio_pre_clitic_pronouns_per_token N4 0.007247368146758391\n",
      "ratio_named_entities_per_token N4 0.06924860872846722\n",
      "ratio_aux_verbs_per_token N4 0.03962372108752811\n",
      "ratio_subordination_per_token N4 0.06212375268046997\n",
      "ratio_passive_per_token N4 0.007158567017721947\n",
      "sophisticated_ratio N4 0.6450123998532469\n",
      "concrete_ratio N4 0.682886461279756\n",
      "hapax_legomena_ratio_lemma N4 0.632650228299069\n",
      "ratio_aux_verbs_per_verb N4 0.4379845956354301\n",
      "ratio_subordination_per_verb N4 0.5052643784786642\n",
      "ratio_passive_per_verb N4 0.07373271889400922\n",
      "ratio_coordination_per_token N4 0.05984150055370985\n",
      "total_token_ratio_coordination N4 0.08307552862857989\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:05:33.219697Z",
     "start_time": "2025-03-28T17:05:33.215675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./thresholds_v4.json' , 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for level in classes.values():\n",
    "    print(thresholds[level][\"document-token-level\"] == data[level][\"document-token-level\"])"
   ],
   "id": "1b084a47f42191ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "efd8635a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:05:58.394241Z",
     "start_time": "2025-03-28T17:05:56.419614Z"
    }
   },
   "source": [
    "sentence_level= {\n",
    "      \"parse_depth\": None,\n",
    "      \"words_after_verb\": None,\n",
    "      \"words_before_verb\": None,\n",
    "      \"sentence_length\": None\n",
    "    }\n",
    "\n",
    "for label, level in classes.items():\n",
    "    \n",
    "    indexes = df[df[\"gold_score_20_label\"] == label].index\n",
    "    \n",
    "    dictionnary = sentence_level.copy()\n",
    "\n",
    "    for phenomenon in dictionnary.keys():\n",
    "        values = []\n",
    "        for i in indexes:\n",
    "            with open('%s/%s.json' %(outputs_path,i), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            '''if 'error' in data.keys() :\n",
    "                errors.append(i)\n",
    "                continue'''\n",
    "            for k, v in data['sentences'].items():\n",
    "                values.append(v['features'][phenomenon])\n",
    "        #values = [x for x in values if x != 0]\n",
    "        lower_bound, upper_bound = get_bounds(values)\n",
    "        print(phenomenon, lower_bound, upper_bound)\n",
    "        dictionnary[phenomenon] = round(upper_bound, 4)\n",
    "        \n",
    "    thresholds[level][\"sentence-level\"] = dictionnary"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_depth 1.5 5.5\n",
      "words_after_verb -2.0 6.0\n",
      "words_before_verb -0.5 3.5\n",
      "sentence_length -2.125 18.875\n",
      "parse_depth 0.0 8.0\n",
      "words_after_verb 0.5 4.5\n",
      "words_before_verb -2.0 6.0\n",
      "sentence_length -6.5 29.5\n",
      "parse_depth 0.0 8.0\n",
      "words_after_verb 0.5 4.5\n",
      "words_before_verb -2.0 6.0\n",
      "sentence_length -11.5 40.5\n",
      "parse_depth 1.0 9.0\n",
      "words_after_verb 0.5 4.5\n",
      "words_before_verb -2.0 6.0\n",
      "sentence_length -15.125 51.875\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:06:00.838719Z",
     "start_time": "2025-03-28T17:06:00.833973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./thresholds_v4.json' , 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for level in classes.values():\n",
    "    print(thresholds[level][\"sentence-level\"] == data[level][\"sentence-level\"])"
   ],
   "id": "7c164f8ce8aed486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "ed880057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T17:01:05.345765Z",
     "start_time": "2025-03-27T17:01:05.341372Z"
    }
   },
   "source": [
    "with open('thresholds_v1.json', 'w') as f:\n",
    "    json.dump(thresholds, f)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "document_document_level = {\n",
    "    \"lexical_diversity\": None}"
   ],
   "id": "3f4f3ce57986f6ed"
  },
  {
   "cell_type": "code",
   "id": "bb16d863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:13:12.554628Z",
     "start_time": "2025-03-28T17:13:12.551287Z"
    }
   },
   "source": [
    "document_document_level = {\n",
    "    \"lexical_diversity\": None}\n",
    "\n",
    "token_level_high = {\n",
    "      \"word_length\": None,\n",
    "      \"word_syllables\": None,\n",
    "      \"ortho_neighbors\": None,\n",
    "      \"ortho_neighbors_+freq_cum\": None,\n",
    "      \"age_of_acquisition\": None,\n",
    "      \"complexity\": None\n",
    "    }\n",
    "\n",
    "token_level_low = {\n",
    "      \"familiarity\": None,\n",
    "      \"lexical_frequency\": None\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "8b554182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:06:17.185618Z",
     "start_time": "2025-03-28T17:06:14.097902Z"
    }
   },
   "source": [
    "for label, level in classes.items():\n",
    "\n",
    "    indexes = df[df[\"gold_score_20_label\"] == label].index\n",
    "\n",
    "    dictionnary = token_level_high.copy()\n",
    "\n",
    "    for phenomenon in dictionnary.keys():\n",
    "        values = []\n",
    "        for i in indexes:\n",
    "            with open('%s/%s.json' %(outputs_path, i), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            if 'error' in data.keys() :\n",
    "                errors.append(i)\n",
    "                continue\n",
    "            for k, v in data['sentences'].items():\n",
    "                for k1, v1 in v['words'].items():\n",
    "                    values.append(v1[phenomenon])\n",
    "        values = [x for x in values if x != 'na']\n",
    "        lower_bound, upper_bound = get_bounds(values)\n",
    "        print(phenomenon, level, round(upper_bound, 4))\n",
    "        dictionnary[phenomenon] = round(upper_bound, 4)\n",
    "\n",
    "    thresholds[level][\"token-level-high\"] = dictionnary\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_length N1 9.5\n",
      "word_syllables N1 2.5\n",
      "ortho_neighbors N1 37.0\n",
      "ortho_neighbors_+freq_cum N1 88770.55\n",
      "age_of_acquisition N1 8.163\n",
      "complexity N1 3.5\n",
      "word_length N2 12.0\n",
      "word_syllables N2 1.0\n",
      "ortho_neighbors N2 34.5\n",
      "ortho_neighbors_+freq_cum N2 61345.485\n",
      "age_of_acquisition N2 7.9794\n",
      "complexity N2 6.0\n",
      "word_length N3 12.0\n",
      "word_syllables N3 3.5\n",
      "ortho_neighbors N3 34.5\n",
      "ortho_neighbors_+freq_cum N3 61339.02\n",
      "age_of_acquisition N3 7.7236\n",
      "complexity N3 3.5\n",
      "word_length N4 12.0\n",
      "word_syllables N4 3.5\n",
      "ortho_neighbors N4 34.5\n",
      "ortho_neighbors_+freq_cum N4 61344.765\n",
      "age_of_acquisition N4 7.1785\n",
      "complexity N4 6.0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:06:21.475707Z",
     "start_time": "2025-03-28T17:06:21.472155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./thresholds_v4.json' , 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for level in classes.values():\n",
    "    print(thresholds[level][\"token-level-high\"] == data[level][\"token-level-high\"])"
   ],
   "id": "9768847e55b44f40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:06:47.818327Z",
     "start_time": "2025-03-28T17:06:46.753616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for label, level in classes.items():\n",
    "\n",
    "    indexes = df[df[\"gold_score_20_label\"] == label].index\n",
    "\n",
    "    dictionnary = token_level_low.copy()\n",
    "\n",
    "    for phenomenon in dictionnary.keys():\n",
    "        values = []\n",
    "        for i in indexes:\n",
    "            with open('%s/%s.json' %(outputs_path, i), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            if 'error' in data.keys() :\n",
    "                errors.append(i)\n",
    "                continue\n",
    "            for k, v in data['sentences'].items():\n",
    "                for k1, v1 in v['words'].items():\n",
    "                    values.append(v1[phenomenon])\n",
    "        values = [x for x in values if x != 'na']\n",
    "        #print(phenomenon, values)\n",
    "        lower_bound, upper_bound = get_bounds(values)\n",
    "        print(phenomenon, lower_bound, upper_bound)\n",
    "        dictionnary[phenomenon] = round(lower_bound, 4)\n",
    "\n",
    "    thresholds[level][\"token-level-low\"] = dictionnary"
   ],
   "id": "a86977d19a7a8a87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "familiarity 2.6964285714285654 9.410714285714285\n",
      "lexical frequency -9752.72999999975 16254.54999999985\n",
      "familiarity 3.0535714285714413 9.196428571428559\n",
      "lexical frequency -13098.85499999975 21831.42499999985\n",
      "familiarity 3.0535714285714413 9.196428571428559\n",
      "lexical frequency -13098.85499999975 21831.42499999985\n",
      "familiarity 3.11071428571429 9.16214285714285\n",
      "lexical frequency -13192.70999999975 21987.84999999985\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:06:52.033604Z",
     "start_time": "2025-03-28T17:06:52.027536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./thresholds_v4.json' , 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for level in classes.values():\n",
    "    print(thresholds[level][\"token-level-low\"] == data[level][\"token-level-low\"])"
   ],
   "id": "6300a4eeac590614",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:55:46.156629Z",
     "start_time": "2025-03-27T16:55:46.151756Z"
    }
   },
   "cell_type": "code",
   "source": "lower_bound",
   "id": "1e7922150e9af0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13192.70999999975"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:53:50.535824Z",
     "start_time": "2025-03-27T16:53:50.533182Z"
    }
   },
   "cell_type": "code",
   "source": "v1",
   "id": "72dbe5e96d44eb47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'Prévision',\n",
       " 'id': 1,\n",
       " 'lemma': 'prévision',\n",
       " 'word_length': 9,\n",
       " 'word_syllables': 3,\n",
       " 'ortho_neighbors': 2,\n",
       " 'ortho_neighbors_+freq_cum': 43.96,\n",
       " 'age_of_acquisition': 'na',\n",
       " 'familiarity': 4.07000017166138,\n",
       " 'lexical frequency:': 7.03,\n",
       " 'complexity:': 0,\n",
       " 'passive': 'O',\n",
       " 'coordination': {},\n",
       " 'clitic_pronouns': 'false',\n",
       " 'aux_verbs': 'O',\n",
       " 'named_entities': 'O',\n",
       " 'subordination': [],\n",
       " 'np_pp_modifiers': {'ids': [2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   10,\n",
       "   9,\n",
       "   16,\n",
       "   15,\n",
       "   19,\n",
       "   17,\n",
       "   21,\n",
       "   20,\n",
       "   23,\n",
       "   22,\n",
       "   24,\n",
       "   25,\n",
       "   27,\n",
       "   26,\n",
       "   28],\n",
       "  'texts': ['météo',\n",
       "   'Bruxelles',\n",
       "   'Mardi',\n",
       "   '12',\n",
       "   'décembre',\n",
       "   'Sainte',\n",
       "   'Chantal',\n",
       "   'de',\n",
       "   'Couché',\n",
       "   '08:33',\n",
       "   'soleil',\n",
       "   'de',\n",
       "   'Matin',\n",
       "   '16:38',\n",
       "   '°',\n",
       "   '7',\n",
       "   'C',\n",
       "   'Après-midi',\n",
       "   '°',\n",
       "   '11',\n",
       "   'C']}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
